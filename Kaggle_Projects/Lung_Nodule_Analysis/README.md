## 肺結節分析專案 (Lung Nodule Analysis)  
Reference：Deep Learning with PyTorch, Eli Stevens, Luca Antiga, and Thomas Viehmann  
Data Source：https://luna16.grand-challenge.org/  
此專案是參照Deep Learning with PyTorch之LUNA分析專案，將此專案實做於Kaggle平台上，並做模型訓練及分析。

#### 專案內容
此專案主要目的是要從CT掃描圖片中，辨識出肺結節並加以分析是否為惡性結節。  

本專案將作業切分為四個部分，分別為：  
- **[肺結節分類](./README.md)**	-         建立可處理3D-CT影像之CNN模型，並載入結節資料加以訓練。  
- **[結節影像切割](./README.md)** -  建立Unet影像分割模型，將資料處理為2D批次圖像作為輸入資料格式，並載入結節資料訓練模型。  
- **[惡性結節分類](./README.md)** -       使用結節分類模型並作遷移訓練，載入惡性結節資料並做訓練。  
- **[整合模型並分析](./README.md)** -       整合上述3個模型，建立CT掃描程序，並加以分析。  

#### LUNA Grand Challenge 簡介

<details>
<summary>點擊展開說明</summary>
  
肺癌是全球癌症相關死亡的主要原因。美國的國家肺癌篩查試驗（NLST）顯示，對於高風險人群，使用年度低劑量電腦斷層掃描（CT）進行肺癌篩查比使用年度胸部X光篩查能降低20%的肺癌死亡率。2013年，美國預防服務工作組（USPSTF）對高風險人群的低劑量CT篩查給予B級推薦，2015年初，美國醫療保險和醫療補助服務中心（CMS）批准了對醫療保險受益者的CT肺癌篩查。隨著這些發展，使用低劑量CT的肺癌篩查計劃正在美國和其他國家實施。當篩查大規模實施時，計算機輔助檢測（CAD）對肺結節的檢測可能發揮重要作用。  
  
大型評估研究對不同先進CAD(Computer-aided detection)系統的性能進行調查較少。因此，我們使用大型公開的LIDC-IDRI數據集組織了一個新穎的CAD檢測挑戰。挑戰的詳細描述現在已在本文中提供。我們認為這個挑戰對於可靠地比較CAD算法以及鼓勵使用先進計算機視覺技術開發新算法具有重要意義。  

</details>

## 程式說明1 - 肺結節分類

- Core: GPU T4 x2
    
程式項目內容：
<details>
<summary>程式項目內容說明</summary>

- **公用程式**
  - Install Libraries - 安裝必要套件
  - Utils - 格式轉換、Log、訓練輔助程式
  - Disk - 快取存取程式
  - Visialize - 圖片顯示程式

- **資料集**
  - Datasets - 建立資料集程式
  - Nodule Sample - 範例顯示

- **模型**
  - Model - 建立模型程式

- **訓練程式**
  - Training - 建立訓練程式
  - Prepare Catch - 資料載入快取程式

- **訓練結果**
  - Start Training - 開始訓練及訓練結果

</details>

執行步驟說明：  
- 資料來源說明
    
  此專案資料來源為斷層掃描**3D圖像檔**(.mhd)，每個檔案大小400～500MB。此專案擷取0~5subset，一共534個檔案。  
  若載入記憶體需要240GB以上之記憶體，因為Kaggle的GPU上提供15G快取記憶體，所以此專案將檔案快取存入硬碟空間以減少記憶體之消耗，
  又因平台上只提供19.5G之儲存空間，故此專案在此需減少訓練樣本數，此模型抽取之樣本總數為**30000筆**資料。
  *(這裡我們使用SimpleITK讀取.mhd檔案)
    
  資料來源提供資料訊息一共包含： 序號, 結節中心座標(xyz), 是否為結節, 直徑, 是否為惡性。
    
- 資料處理
    
  此模型為結節的判斷，所以將資料中有關結節之資訊擷取出，包含結節及非結節資料。  
  因為我們資料來源為一個3D圖檔，我們需要知道結節位置，所以須將座標(xyz)轉換為位置(IRC)(Index,Raw,Col)資訊。  
  這裡不將整個CT作為Input，而是將結節從資料來源中切下為一個切塊(chunk)，以此作為訓練之輸入。  
  處理完後的資料包含樣本**切塊、中心座標、體素大小**、方向矩陣等。  
  在此我們將每個結節資料包裝為一個**Ct**(class)  
    
- 建立Dataset
    
  建立一個Pytorch Dataset以供訓練使用，在此將資料區分為訓練及驗證資料，以**10：1**之比例做分配。  
  這裡有發現一個問題，就是非結節資料遠比是結節資料多，以此訓練會發現模型會將結節都判定為非結節。  
  故此這裡做資料平衡處理，就是將結節及非結節資料分開，以**1:1交錯輸入**訓練。  
  在此又會發生結節資料重複輸入狀況，所以我們做一個將輸入資料做**隨機處理**(翻轉,縮放,隨機排列等)，避免過度適配情形發生。  
  整理後資料**輸出為結節張量、是否為結節標籤、序號、中心位置張量**  
    
- 建立模型
    
  此程式使用CNN模型，輸入為**3D資料**，輸出為二元標籤及機率。  
  此模型架構分為**尾部(tail)、主體(body)、頭部(head)**。  
  尾部的部分為輸入資料，做一個批次正規劃。  
  主體的部分由**4個卷積區塊**組成，每個卷積區塊由2個卷積層一個池化層組成。  
  頭部的部分，先將資料扁平化，再輸入**全連接層**，  
  **最終輸出兩個資料：二元原始資料、Softmax計算出之機率**
  此模型初始化時，使用**Kaiming 初始化**，初始化各神經網路權重
  ```
  ----------------------------------------------------------------
          Layer (type)               Output Shape         Param #
  ================================================================
         BatchNorm3d-1        [-1, 1, 32, 48, 48]               2
              Conv3d-2        [-1, 8, 32, 48, 48]             224
                ReLU-3        [-1, 8, 32, 48, 48]               0
              Conv3d-4        [-1, 8, 32, 48, 48]           1,736
                ReLU-5        [-1, 8, 32, 48, 48]               0
           MaxPool3d-6        [-1, 8, 16, 24, 24]               0
           LunaBlock-7        [-1, 8, 16, 24, 24]               0
              Conv3d-8       [-1, 16, 16, 24, 24]           3,472
                ReLU-9       [-1, 16, 16, 24, 24]               0
             Conv3d-10       [-1, 16, 16, 24, 24]           6,928
               ReLU-11       [-1, 16, 16, 24, 24]               0
          MaxPool3d-12        [-1, 16, 8, 12, 12]               0
          LunaBlock-13        [-1, 16, 8, 12, 12]               0
             Conv3d-14        [-1, 32, 8, 12, 12]          13,856
               ReLU-15        [-1, 32, 8, 12, 12]               0
             Conv3d-16        [-1, 32, 8, 12, 12]          27,680
               ReLU-17        [-1, 32, 8, 12, 12]               0
          MaxPool3d-18          [-1, 32, 4, 6, 6]               0
          LunaBlock-19          [-1, 32, 4, 6, 6]               0
             Conv3d-20          [-1, 64, 4, 6, 6]          55,360
               ReLU-21          [-1, 64, 4, 6, 6]               0
             Conv3d-22          [-1, 64, 4, 6, 6]         110,656
               ReLU-23          [-1, 64, 4, 6, 6]               0
          MaxPool3d-24          [-1, 64, 2, 3, 3]               0
          LunaBlock-25          [-1, 64, 2, 3, 3]               0
             Linear-26                    [-1, 2]           2,306
            Softmax-27                    [-1, 2]               0
  ================================================================
  Total params: 222,220
  Trainable params: 222,220
  Non-trainable params: 0
  ----------------------------------------------------------------
  Input size (MB): 0.28
  Forward/backward pass size (MB): 25.96
  Params size (MB): 0.85
  Estimated Total Size (MB): 27.09
  ----------------------------------------------------------------
  ```  
- 訓練模型  
    
  此訓練**批次大小為32**，一次訓練輸入32筆資料，並做資料平衡及強化資料多變性。  
  建立**初始化模型**(LunaModel)及**優化器(GCD)**，並將Model放置(平行)於GPU*2上。  
  建立**DataLoader**，包含訓練資料(train_dl)及驗證資料(val_dl)。  
  建立損失函數，這裡使用**交叉熵損失函數**，並使其返回每個樣本的損失值，  
  將模型輸出之logits及資料Label輸入**計算損失**，並回傳損失。  
  將損失進行**反向傳播**，再使用優化器計算梯度**更新模型參數**(weights,bias)。  
  訓練設定為每5次訓練進行一次驗證。  
  反覆迭代周期，完成模型訓練。  
    
  訓練使用**Tensorboard**來記錄訓練資訊，訓練資訊內容如下：  
  **損失**：loss/all, loss/neg, loss/pos  
  **準確率**：correct/all, correct/neg, correct/pos  
  **預測**：pr/precision(準確率), pr/recall(招回率)  
  **F1 score**: pr/f1_score, 公式為 2*(precision*recall)/(precision+recall)  
  F1分數介於0～1之間，越大表示分類模型表現越好。  
  這裡我們需要準確率及招回率皆上升才判定為良好模型。  
    
  建立一個評估函數，使其可再輸入資料中評估及紀錄執行時間(enumerateWithEstimate)。  
  在訓練之前預先將快取訓練資料存入硬碟空間中，以加速訓練速度，並減少記憶體使用率。  
    
- 訓練結果  

  此訓練使用平衡資料及資料擴增函數，並迭代10次做模型訓練。結果如下：
  ```
  E1 trn      0.2103 loss,  91.1% correct, 0.9284 precision, 0.8901 recall, 0.9089 f1 score
  E1 trn_neg  0.1939 loss,  93.1% correct (93139 of 100000)
  E1 trn_pos  0.2267 loss,  89.0% correct (89010 of 100000)
  ...
  E1 val      0.0748 loss,  97.5% correct, 0.5260 precision, 0.9643 recall, 0.6807 f1 score
  E1 val_neg  0.0744 loss,  97.5% correct (2844 of 2917)
  E1 val_pos  0.0893 loss,  96.4% correct (81 of 84)
  ...
  E10 trn      0.0467 loss,  98.5% correct, 0.9845 precision, 0.9850 recall, 0.9848 f1 score
  E10 trn_neg  0.0528 loss,  98.5% correct (98454 of 100000)
  E10 trn_pos  0.0406 loss,  98.5% correct (98502 of 100000)
  ...
  E10 val      0.0595 loss,  97.8% correct, 0.5646 precision, 0.9881 recall, 0.7186 f1 score
  E10 val_neg  0.0594 loss,  97.8% correct (2853 of 2917)
  E10 val_pos  0.0617 loss,  98.8% correct (83 of 84)
  ```
  可以看到訓練後的模型表現不錯，在陽性及陰性的正確率都有97%以上。  
  Tensorboard訓練頻估指標：  
    
  可以看出此訓練的損失有不斷下降的趨勢，但驗證的損失接近持平甚是有突然升高情形，  
  研判此模型有些許的過渡適配，若繼續訓練會有反效果。  
    
  在預測的部份我們可以看到，此模型的準確率大概6~7成左右。  
    
  若要加強模型的表現，可以做以下修正：  
  1.增加訓練樣本數，使用更多樣化的樣本作訓練減少過度適配，提高準確率。  
  2.修改模型，增加模型參數，及使用Dropout，都可以讓模型減少過度適配現象。  
  3.修改資料擴增函數，讓本為少數的陽性樣本，在重複訓練時有更多的變化。  
  

## 程式說明2 - 結節影像切割

- Core: GPU T4 x2

程式項目內容：
<details>
<summary>程式項目內容說明</summary>

- **公用程式**
  - Install Libraries - 安裝必要套件
  - Utils - 格式轉換、Log、訓練輔助程式
  - Disk - 快取存取程式
  - Visialize - 圖片顯示程式

- **資料集**
  - Datasets - 建立資料集程式

- **模型**
  - Model - 建立模型程式

- **訓練程式**
  - Training - 建立訓練程式
  - Prepare Catch - 資料載入快取程式

- **訓練結果**
  - Start Training - 開始訓練及訓練結果

</details>

執行步驟說明：  
- 資料來源說明
    
  資料來源和程式1相同，需要用到結節資料，不同的是這次在影像上需要做更多的處理。
    
- 資料處理

  此模型為分割結節影像，所以我們需要取得所有結節資料，以此作為分割模型的訓練樣本。
  這裡不將3D資料直接輸入模型處理，因為這方式所需的記憶體太過龐大，沒有這樣的資源，
  故此將資料改為2D切片作為資料的輸入，可以大大減少記憶體消耗，此方法也有缺點，就是遺失了切片及切片空間的關係。
  模型可以輸入任意影像大小進行分割，在此我們不將整張CT圖輸入做訓練，
  只針對結節的部分，產生96*96*結節厚度大小的圖片集。
  在此需要產生結節遮罩，這裡使用已中心座標往外尋找至低密度(-700)的位置作為結節區塊的判定。
  處理完後的資料包含樣本**切塊圖檔、結節遮罩切塊、中心位置**, 結節的Index等。  
  在此我們將每個結節資料包裝為一個**Ct**(class) 
  
- 建立Dataset  

  建立兩個Dataset，一個為所有資料的資料集(包含所有資料)，一個為訓練用資料集(繼承所有資料集，但只回傳為結節的資料)。
  將資料區分為訓練及驗證資料，以**10：1**之比例做分配。
  切片數量的部分這裡取結節中心前後3張，共7張切片。 
  此處的訓練樣本將96*96大小的圖檔隨機取出64*64大小，作為資料擴增的方式之一。  
  整理後資料**輸出為結節張量、遮罩張量、序號、切片中心索引**  

- 建立模型
    
  我們需要做結節影像的分割，在此使用U-Net模型分割影像資料，輸入資料為批次2D圖檔，
  輸出為經過標注的完整影像，有了這些預測的結節影像，以便給後續分類模型進行處理。
  這裡的U-Net我們做一些變化，將其包裝分為三層：
  第一層處理輸入資料，將其批次標準化。
  第二層為U-Net主體，將圖片做處理。
  第三層將輸出結果壓縮到 0 到 1 的範圍。
  此模型初始化時，使用**Kaiming 初始化**，初始化各神經網路權重。
  ```
  ----------------------------------------------------------------
          Layer (type)               Output Shape         Param #
  ================================================================
         BatchNorm2d-1            [-1, 7, 64, 64]              14
              Conv2d-2           [-1, 16, 64, 64]           1,024
                ReLU-3           [-1, 16, 64, 64]               0
         BatchNorm2d-4           [-1, 16, 64, 64]              32
              Conv2d-5           [-1, 16, 64, 64]           2,320
                ReLU-6           [-1, 16, 64, 64]               0
         BatchNorm2d-7           [-1, 16, 64, 64]              32
       UNetConvBlock-8           [-1, 16, 64, 64]               0
              Conv2d-9           [-1, 32, 32, 32]           4,640
               ReLU-10           [-1, 32, 32, 32]               0
        BatchNorm2d-11           [-1, 32, 32, 32]              64
             Conv2d-12           [-1, 32, 32, 32]           9,248
               ReLU-13           [-1, 32, 32, 32]               0
        BatchNorm2d-14           [-1, 32, 32, 32]              64
      UNetConvBlock-15           [-1, 32, 32, 32]               0
             Conv2d-16           [-1, 64, 16, 16]          18,496
               ReLU-17           [-1, 64, 16, 16]               0
        BatchNorm2d-18           [-1, 64, 16, 16]             128
             Conv2d-19           [-1, 64, 16, 16]          36,928
               ReLU-20           [-1, 64, 16, 16]               0
        BatchNorm2d-21           [-1, 64, 16, 16]             128
      UNetConvBlock-22           [-1, 64, 16, 16]               0
    ConvTranspose2d-23           [-1, 32, 32, 32]           8,224
             Conv2d-24           [-1, 32, 32, 32]          18,464
               ReLU-25           [-1, 32, 32, 32]               0
        BatchNorm2d-26           [-1, 32, 32, 32]              64
             Conv2d-27           [-1, 32, 32, 32]           9,248
               ReLU-28           [-1, 32, 32, 32]               0
        BatchNorm2d-29           [-1, 32, 32, 32]              64
      UNetConvBlock-30           [-1, 32, 32, 32]               0
        UNetUpBlock-31           [-1, 32, 32, 32]               0
    ConvTranspose2d-32           [-1, 16, 64, 64]           2,064
             Conv2d-33           [-1, 16, 64, 64]           4,624
               ReLU-34           [-1, 16, 64, 64]               0
        BatchNorm2d-35           [-1, 16, 64, 64]              32
             Conv2d-36           [-1, 16, 64, 64]           2,320
               ReLU-37           [-1, 16, 64, 64]               0
        BatchNorm2d-38           [-1, 16, 64, 64]              32
      UNetConvBlock-39           [-1, 16, 64, 64]               0
        UNetUpBlock-40           [-1, 16, 64, 64]               0
             Conv2d-41            [-1, 1, 64, 64]              17
               UNet-42            [-1, 1, 64, 64]               0
            Sigmoid-43            [-1, 1, 64, 64]               0
  ================================================================
  Total params: 118,271
  Trainable params: 118,271
  Non-trainable params: 0
  ----------------------------------------------------------------
  Input size (MB): 0.11
  Forward/backward pass size (MB): 13.19
  Params size (MB): 0.45
  Estimated Total Size (MB): 13.75
  ----------------------------------------------------------------
  ```
- 訓練模型
  
  模型參數的部分，Unet輸入通道為7個，輸出為二分類，Unet深度為3層，寬度係數為4，
  輸出特徵圖的大小與輸入相同，解碼器部分上採樣的方法為上採樣卷積，使用批次標準化。
  
  訓練批次為一次16個樣本，並進行資料擴增。
  建立**初始化模型**(UNetWrapper, SegmentationAugmentation)，此處包含兩個模型，
  另一個資料擴增模型是為了利用GPU，將資料放入GPU中做處理。
  建立**DataLoader**，包含訓練資料(train_dl)及驗證資料(val_dl)，訓練資料是取用全結節資料做訓練。


  建立**初始化模型**(LunaModel)及**優化器(GCD)**，並將Model放置(平行)於GPU*2上。  
  建立**DataLoader**，包含訓練資料(train_dl)及驗證資料(val_dl)。  
  建立損失函數，這裡使用**交叉熵損失函數**，並使其返回每個樣本的損失值，  
  將模型輸出之logits及資料Label輸入**計算損失**，並回傳損失。  
  將損失進行**反向傳播**，再使用優化器計算梯度**更新模型參數**(weights,bias)。  
  訓練設定為每5次訓練進行一次驗證。  
  反覆迭代周期，完成模型訓練。  

  









<!--
隱藏的文字：以下是各個功能模塊的詳細信息。
-->

## Features

<details>
  <summary>點擊展開詳細功能說明</summary>


| 公用程式 | 資料集 | 模型 | 訓練程式 | 訓練結果 |
|----------|--------|------|----------|----------|
| Install Libraries | Datasets | Model | Training | Start Training |
| Utils | Nodule Sample | | Prepare Catch | |
| Disk | | | | |
| Visualize | | | | |

